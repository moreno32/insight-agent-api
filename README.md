# Amplify AI üöÄ

### Tu copiloto de IA para crear contenido de marca y campa√±as de marketing impactantes.

![Amplify AI Demo GIF](https://your-image-placeholder.com/amplify-ai-demo.gif)
*Nota: Reemplaza esta URL con un GIF de tu aplicaci√≥n en acci√≥n una vez que tengas el MVP.*

---

## üìù Descripci√≥n General

**Amplify AI** es un proyecto capstone end-to-end que demuestra el ciclo de vida completo de un producto de IA. La plataforma act√∫a como un asistente de marketing inteligente para PYMES, permiti√©ndoles generar contenido para redes sociales de forma r√°pida, sencilla y consistente con su identidad de marca.

El sistema se basa en un **agente multimodal avanzado construido con LangChain**. A trav√©s de una interfaz de Streamlit, el usuario rellena un **formulario estructurado** que incluye su idea, un manual de marca en formato Markdown y sus im√°genes de estilo. Este input controlado garantiza un procesamiento de alta calidad, que el agente utiliza para orquestar un pipeline de RAG sofisticado y producir contenido √∫nico.

Este proyecto integra **IA Generativa**, **Machine Learning cl√°sico** y pr√°cticas modernas de **MLOps/DevOps**, demostrando una competencia integral en la ingenier√≠a de IA.

## üåü Caracter√≠sticas Principales

*   **Agente Inteligente con LangChain:** El n√∫cleo del sistema es un agente que orquesta de manera aut√≥noma todo el flujo de trabajo.
*   **Input Estructurado y Controlado:** El usuario rellena un formulario, garantizando que el `brand_guide.md` siempre tenga un formato consistente para un chunking y procesamiento √≥ptimos.
*   **Comprensi√≥n Multimodal del Contexto:** Procesa tanto texto como im√°genes para un entendimiento profundo de la identidad de la marca.
*   **Pipeline de RAG Avanzado:** Utiliza t√©cnicas de retrieval sofisticadas (`MultiQueryRetriever`, `MMR`) y una estrategia de LLM de dos niveles para maximizar la calidad y eficiencia.
*   **Interfaz Interactiva:** Una aplicaci√≥n web amigable construida con **Streamlit**.
*   **Arquitectura Lista para Producci√≥n:** Utiliza **Ollama** para el servicio de LLMs, una soluci√≥n contenerizable y escalable.

## üõ†Ô∏è Arquitectura y Stack Tecnol√≥gico

Amplify AI est√° construido sobre un stack moderno y open-source, con un fuerte enfoque en el control local de los modelos y la modularidad a trav√©s de LangChain.

![Architecture Diagram](https://your-image-placeholder.com/architecture-diagram.png)
*Nota: Crea un diagrama simple (con tools como diagrams.net o Excalidraw) que muestre el flujo completo.*

### **Componentes Principales:**

*   **Frontend:** **Streamlit**
*   **Backend:** **API con FastAPI**
*   **Orquestaci√≥n del Agente:** **LangChain**
*   **Modelo de Clasificaci√≥n (Intenci√≥n):** **Scikit-learn**
*   **Modelo de Difusi√≥n (Im√°genes):** **Stable Diffusion**

### **El Pipeline de RAG con LangChain**

#### 1. LLM (Large Language Model) - Estrategia de Dos Niveles
*   **Plataforma:** **Ollama** sirve los LLMs localmente. Es una soluci√≥n robusta, r√°pida y desplegable, ideal para un entorno de producci√≥n.
*   **LLM Principal (Generaci√≥n):** Se utiliza **`qwen3:8b`** para la generaci√≥n final de texto. Su tama√±o ofrece un excelente equilibrio entre creatividad, calidad de razonamiento y velocidad.
*   **LLM Secundario (Retrieval):** Para la tarea de generar variantes de consulta en el `MultiQueryRetriever`, se usa un modelo m√°s peque√±o y r√°pido como **`qwen3:4b`** para minimizar la latencia y optimizar el uso de recursos.

#### 2. Carga y Divisi√≥n de Documentos (Loaders & Splitters)
*   **Tecnolog√≠a:** `UnstructuredMarkdownLoader` ‚Üí `MarkdownHeaderTextSplitter`.
*   **Estrategia:** El sistema se basa en un input de Markdown estructurado a trav√©s de un formulario en el frontend. Esto **garantiza un chunking de alta calidad**, ya que la estructura de encabezados (`#`, `##`) es siempre consistente, preservando la jerarqu√≠a del documento en los metadatos de cada chunk.

#### 3. Embeddings (Vectorizaci√≥n)
*   **Tecnolog√≠a:** `langchain_community.embeddings.HuggingFaceEmbeddings`.
*   **Modelo:** Se utiliza **`paraphrase-multilingual-mpnet-base-v2`** para asegurar una comprensi√≥n sem√°ntica de alta calidad tanto en ingl√©s como en espa√±ol, lo cual es crucial para el caso de uso.

#### 4. Almac√©n de Vectores (Vector Store)
*   **Tecnolog√≠a:** `langchain_community.vectorstores.Chroma`.
*   **Estrategia:** Se configura para **persistir en disco** (`persist_directory='db/chroma'`), optimizando el rendimiento al evitar la re-indexaci√≥n en cada ejecuci√≥n.

#### 5. Recuperaci√≥n de Informaci√≥n (Retrievers)
*   **`MultiQueryRetriever`:** Utiliza el LLM secundario (`qwen3:4b`) para reescribir la consulta del usuario en m√∫ltiples variantes, mejorando significativamente el recall de la informaci√≥n.
*   **B√∫squeda MMR (`Maximal Marginal Relevance`):** Se usa para seleccionar el conjunto final de documentos, asegurando un balance √≥ptimo entre relevancia y diversidad para evitar pasar contexto redundante al LLM principal.

## üöÄ C√≥mo Empezar (Desarrollo Local)

### **Prerrequisitos**

*   Python 3.9+
*   Docker y Docker Compose
*   Git
*   **Ollama instalado y en ejecuci√≥n:**
    1.  Descarga e instala [Ollama](https://ollama.com/).
    2.  Ejecuta los siguientes comandos en tu terminal para descargar los modelos necesarios:
        ```bash
        ollama pull qwen3:8b
        ollama pull qwen3:4b
        ```

### **Instalaci√≥n y Ejecuci√≥n**

1.  **Clona el repositorio:**
    ```bash
    git clone https://github.com/moreno32/amplify-ai.git
    cd amplify-ai
    ```

2.  **Configura las variables de entorno:**
    Crea un archivo `.env` a partir de `env.example`. Las URLs de Ollama ya deber√≠an estar configuradas por defecto para un entorno local.
    ```bash
    cp .env.example .env
    ```

3.  **Construye y levanta los contenedores:**
    ```bash
    docker-compose up --build
    ```

4.  **Accede a la aplicaci√≥n:**
    *   **Frontend (Streamlit):** `http://localhost:8501`
    *   **Backend Docs (FastAPI):** `http://localhost:8000/docs`

## üó∫Ô∏è Roadmap del Proyecto

*   [‚úÖ] **Fase 1: MVP Funcional con Pipeline de RAG Avanzado**
*   [‚¨úÔ∏è] **Fase 2: Contenerizaci√≥n y Despliegue en la Nube**
*   [‚¨úÔ∏è] **Fase 3: Integraci√≥n Multimodal Completa (An√°lisis de Im√°genes)**
*   [‚¨úÔ∏è] **Fase 4: Implementaci√≥n de Nodos de Agente Avanzados (Guardrails, Tools)**
*   [‚¨úÔ∏è] **Fase 5: Framework de Evaluaci√≥n y Monitorizaci√≥n**

## üßë‚Äçüíª Sobre M√≠

¬°Hola! Soy **Daniel Moreno**, un AI Engineer / Data Scientist apasionado por construir productos de IA que resuelven problemas del mundo real. Este proyecto es una demostraci√≥n de mis habilidades en todo el espectro del desarrollo de soluciones de Machine Learning, desde la concepci√≥n hasta la producci√≥n.

**Con√©ctate conmigo:**
*   **Email:** [danielmoreno3291@gmail.com](mailto:danielmoreno3291@gmail.com)
*   **Tel√©fono:** `+34 673 145 358`
*   **Ubicaci√≥n:** Barcelona, Espa√±a
*   **LinkedIn:** [https://www.linkedin.com/in/dmoreno-ai](https://www.linkedin.com/in/dmoreno-ai)
*   **GitHub:** [https://github.com/moreno32](https://github.com/moreno32)
*   **Medium (Blog):** [https://medium.com/@dmoreno-ai](https://medium.com/@dmoreno-ai)
*   **Portafolio:** [https://danielmoreno-ai.netlify.app/](https://danielmoreno-ai.netlify.app/)