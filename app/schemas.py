# -*- coding: utf-8 -*-
"""
Pydantic Schemas (Data Contracts) for the Amplify AI Project.

This module defines the data structures for the API, ensuring data validation,
serialization, and automatic documentation via FastAPI.
"""

# =======================================================================
#  2. PYDANTIC SCHEMAS (DATA CONTRACTS) - Amplify AI (Final)
# =======================================================================
#
# Purpose:
#   - Define the structure and data types for API inputs and outputs.
#   - Pydantic models automatically handle data validation, serialization,
#     and documentation.
#   - These are the "contracts" of the Amplify AI API.
#
# =======================================================================

from pydantic import BaseModel, Field
from typing import List

# =======================================================================
#  API INPUT DEFINITION (CONCEPTUAL)
# =======================================================================

# --- IMPORTANT NOTE ON INPUTS ---
#
# When an API accepts file uploads (like a .md brand guide and images),
# it uses the 'multipart/form-data' content type, not 'application/json'.
#
# In FastAPI, this means inputs are defined directly as parameters in the
# endpoint function's signature, using `Form()` for form fields and `File()`
# for files. They are NOT defined in a single Pydantic input model.
#
# Below is a conceptual representation of how your inputs will be defined
# in your 'endpoints.py' file. This section is for documentation purposes
# to clarify how the API receives its data.
#
# from fastapi import Form, File, UploadFile
# from typing import List
#
# Conceptual Inputs for the /generate endpoint:
#   1. user_prompt: str = Form(..., description="The user's core request, e.g., 'Announce our new fall coffee'.")
#   2. brand_guide_file: UploadFile = File(..., description="The user's brand guide in .md format.")
#   3. style_images: List[UploadFile] = File(..., description="A list of images that represent the brand's visual style.")

# =======================================================================
#  OUTPUT SCHEMAS
# =======================================================================

class ContentGenerationOutput(BaseModel):
    """
    Defines the structured response from the content generation endpoint.
    It includes the final generated content plus rich metadata for transparency
    about the advanced RAG pipeline.
    """
    generated_copy_text: str = Field(
        ...,
        title="Generated Post Copy",
        description="The final, ready-to-publish text for the social media post.",
        example="¬°El oto√±o ya est√° aqu√≠ y nuestro Latte de Calabaza tambi√©n! üçÇüéÉ Ven a probar el sabor de la temporada, hecho con especias naturales y mucho amor."
    )
    generated_image_b64: str = Field(
        ...,
        title="Generated Image (Base64 Encoded)",
        description="The generated image for the post, encoded as a Base64 string.",
        example="iVBORw0KGgoAAAANSUhEUgA..."
    )
    classified_intent: str = Field(
        ...,
        title="Classified User Intent",
        description="The user's intent as predicted by the classification model (e.g., Promotion, Product Launch).",
        example="Lanzamiento de Producto"
    )
    # --- NOVEDAD: Visibilidad del MultiQueryRetriever ---
    generated_queries: List[str] = Field(
        ...,
        title="Generated Sub-Queries (from MultiQueryRetriever)",
        description="The list of alternative questions generated by the retrieval LLM (qwen3:4b) to broaden the search and improve context quality.",
        example=[
            "¬øCu√°les son las mejores estrategias de marketing para lanzar un nuevo caf√© de oto√±o?",
            "¬øC√≥mo crear un post de redes sociales atractivo para una bebida de temporada?",
            "Ideas de texto para promocionar un latte de calabaza."
        ]
    )
    retrieved_context: List[str] = Field(
        ...,
        title="Retrieved Context (from Text and Images)",
        description="The final, most relevant context snippets retrieved by the RAG pipeline, which were fed to the main LLM (qwen3:8b) for generation.",
        example=[
            "Tono de voz: cercano y c√°lido, usar emojis estacionales.",
            "una fotograf√≠a de un latte art en forma de hoja sobre una taza naranja"
        ]
    )

    class Config:
        """Pydantic model configuration for rich examples in documentation."""
        json_schema_extra = {
            "example": {
                "generated_copy_text": "¬°El oto√±o ya est√° aqu√≠ y nuestro Latte de Calabaza tambi√©n! üçÇüéÉ Ven a probar el sabor de la temporada, hecho con especias naturales y mucho amor. #LatteDeCalabaza #Oto√±o",
                "generated_image_b64": "iVBORw0KGgoAAAANSUhEUg...",
                "classified_intent": "Lanzamiento de Producto",
                "generated_queries": [
                    "¬øCu√°les son las mejores estrategias de marketing para lanzar un nuevo caf√© de oto√±o?",
                    "¬øC√≥mo crear un post de redes sociales atractivo para una bebida de temporada?"
                ],
                "retrieved_context": [
                    "Tono de voz: cercano y c√°lido, usar emojis estacionales.",
                    "una fotograf√≠a de un latte art en forma de hoja sobre una taza naranja"
                ]
            }
        }


# =======================================================================
#  UTILITY SCHEMAS
# =======================================================================

class Msg(BaseModel):
    """
    A schema for a generic message response, typically used for
    health check endpoints or simple error feedback.
    """
    message: str